{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# authorship attribution\n",
    "## by: Dekel Mor, Matan Ramati\n",
    "\n",
    "\n",
    "### Introduction and motivation\n",
    "\n",
    "We live in changing times: With the way our social media activity increases, we now have a shift away from traditional communication towards a text-based one, and that made facial recognition and voice recognition irrelevant. While these type of messages may have significant advantages and allows us to persist in a globalized world, some question and problem arise we have to face. Undoubtfully, one crucial ability is the identification of an author through its texts; without direct contact, fakes are elsewhere hardly recognizable. The science of identifying authors by there writing is called Stylometry. With our ability to access big data and having sufficient computational power nowadays, the accuracy we may gain in such kinds of tasks is quite impressive.\n",
    "\n",
    "### the data\n",
    "\n",
    "our required data is a collection of pairs that contains rich text(not formally, because we want to find differences) and the text author identification.\n",
    "because we wand to classify the text by his author.\n",
    "\n",
    "we chose to use blog posts data set contain 681,288 posts of 19,320 bloggers  (more details about the dataset in the link) :\n",
    "https://www.kaggle.com/rtatman/blog-authorship-corpus\n",
    "\n",
    "### Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the imports\n",
    "\n",
    "import sys\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "from nltk.corpus import stopwords\n",
    "from random import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk import NaiveBayesClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "0  2059027             Info has been found (+/- 100 pages,...\n",
       "1  2059027             These are the team members:   Drewe...\n",
       "2  2059027             In het kader van kernfusie op aarde...\n",
       "3  2059027                   testing!!!  testing!!!          \n",
       "4  3581210               Thanks to Yahoo!'s Toolbar I can ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the blogtext file to data frame table\n",
    "df = pd.read_csv('blogtext.csv')\n",
    "\n",
    "# drop the irrelevant columns\n",
    "df = df.drop(['date', 'sign', 'topic', 'age', 'gender'], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "449628     4221\n",
       "734562     2301\n",
       "589736     2294\n",
       "1975546    2261\n",
       "958176     2244\n",
       "1107146    2237\n",
       "303162     2114\n",
       "942828     2068\n",
       "1270648    1951\n",
       "1784456    1843\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the 10 authors with larger quantity of posts\n",
    "df['id'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of posts:  8816\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# keep only the rows of the top 10 authors(by number of posts)\n",
    "top_authors = df['id'].value_counts()[:3].index.tolist()\n",
    "\n",
    "# drop the rows that doesnt belong to authors who in the top 10 list\n",
    "df = df[df['id'].isin(top_authors)]\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "sns.countplot(df['id'], label=\"count\")\n",
    "\n",
    "df.head()\n",
    "\n",
    "print(\"number of posts: \",len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize text\n",
    "for i in range(len(df)):\n",
    "    df.loc[i] = [df.loc[i].id, nltk.word_tokenize(df.loc[i].text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding column length - the number of tokens in post\n",
    "df['length'] = '0'\n",
    "for i in range(len(df)):\n",
    "    df.loc[i] = [df.loc[i].id, df.loc[i].text, len(df.loc[i].text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping rows with length==0\n",
    "for i in range(len(df)):\n",
    "    if( len(df.loc[i].text) == 0 ):\n",
    "        df = df.drop([df.loc[i].name])\n",
    "\n",
    "        \n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding column richness - vocabulary richness, the percent of words who use once\n",
    "df['richness'] = '0'\n",
    "for i in range(len(df)):\n",
    "    df.loc[i] = [df.loc[i].id, df.loc[i].text, df.loc[i].length, (len(set(df.loc[i].text)) / df.loc[i].length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>richness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>589736</td>\n",
       "      <td>[Much, funny, ., 2, points, ., As, mentioned, ...</td>\n",
       "      <td>47</td>\n",
       "      <td>0.787234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>589736</td>\n",
       "      <td>[Harpers, ,, Harpers, ,, everywhere, ., Harper...</td>\n",
       "      <td>93</td>\n",
       "      <td>0.44086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589736</td>\n",
       "      <td>[In, an, earlier, post, ,, Johnathan, said, :,...</td>\n",
       "      <td>327</td>\n",
       "      <td>0.504587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>589736</td>\n",
       "      <td>[I, 'd, post, this, on, the, RTG, Blog, ,, but...</td>\n",
       "      <td>390</td>\n",
       "      <td>0.55641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>589736</td>\n",
       "      <td>[The, answer, to, the, first, question, lies, ...</td>\n",
       "      <td>29</td>\n",
       "      <td>0.827586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text length  richness\n",
       "0  589736  [Much, funny, ., 2, points, ., As, mentioned, ...     47  0.787234\n",
       "1  589736  [Harpers, ,, Harpers, ,, everywhere, ., Harper...     93   0.44086\n",
       "2  589736  [In, an, earlier, post, ,, Johnathan, said, :,...    327  0.504587\n",
       "3  589736  [I, 'd, post, this, on, the, RTG, Blog, ,, but...    390   0.55641\n",
       "4  589736  [The, answer, to, the, first, question, lies, ...     29  0.827586"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the proportion between number of commas & dots to the text length\n",
    "df['commas'] = '0'\n",
    "df['dots'] = '0'\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df.loc[i] = [df.loc[i].id, \n",
    "                 df.loc[i].text, df.loc[i].length, \n",
    "                 df.loc[i].richness, \n",
    "                 df.loc[i].text.count(',')/df.loc[i].length, \n",
    "                 df.loc[i].text.count('.')/df.loc[i].length ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>richness</th>\n",
       "      <th>commas</th>\n",
       "      <th>dots</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>589736</td>\n",
       "      <td>[Much, funny, ., 2, points, ., As, mentioned, ...</td>\n",
       "      <td>47</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.0425532</td>\n",
       "      <td>0.0851064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>589736</td>\n",
       "      <td>[Harpers, ,, Harpers, ,, everywhere, ., Harper...</td>\n",
       "      <td>93</td>\n",
       "      <td>0.44086</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.0860215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589736</td>\n",
       "      <td>[In, an, earlier, post, ,, Johnathan, said, :,...</td>\n",
       "      <td>327</td>\n",
       "      <td>0.504587</td>\n",
       "      <td>0.0489297</td>\n",
       "      <td>0.0275229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>589736</td>\n",
       "      <td>[I, 'd, post, this, on, the, RTG, Blog, ,, but...</td>\n",
       "      <td>390</td>\n",
       "      <td>0.55641</td>\n",
       "      <td>0.0564103</td>\n",
       "      <td>0.0410256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>589736</td>\n",
       "      <td>[The, answer, to, the, first, question, lies, ...</td>\n",
       "      <td>29</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.0344828</td>\n",
       "      <td>0.0344828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text length  richness  \\\n",
       "0  589736  [Much, funny, ., 2, points, ., As, mentioned, ...     47  0.787234   \n",
       "1  589736  [Harpers, ,, Harpers, ,, everywhere, ., Harper...     93   0.44086   \n",
       "2  589736  [In, an, earlier, post, ,, Johnathan, said, :,...    327  0.504587   \n",
       "3  589736  [I, 'd, post, this, on, the, RTG, Blog, ,, but...    390   0.55641   \n",
       "4  589736  [The, answer, to, the, first, question, lies, ...     29  0.827586   \n",
       "\n",
       "      commas       dots  \n",
       "0  0.0425532  0.0851064  \n",
       "1   0.193548  0.0860215  \n",
       "2  0.0489297  0.0275229  \n",
       "3  0.0564103  0.0410256  \n",
       "4  0.0344828  0.0344828  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for id,text(untoken) table. returning dictionary with tokens length, vocabulary richness, commas proportion and dots proportion.\n",
    "def bag_of_words(post):\n",
    "    post = nltk.word_tokenize(post)\n",
    "    post = [w.lower() for w in post]\n",
    "    length = len(post)\n",
    "    if length == 0:\n",
    "        length = 1\n",
    "    richness = len(set(post)) / length\n",
    "    commas = post.count(',')\n",
    "    dots = post.count('.')\n",
    "    post = [w for w in post if not w in stop_words and len(w)>2]\n",
    "    words_dictionary = dict([word, True] for word in FreqDist(post))\n",
    "    words_dictionary['len'] = length\n",
    "    words_dictionary['ric'] = richness\n",
    "    words_dictionary['com'] = commas / length\n",
    "    words_dictionary['dot'] = dots / length\n",
    "    \n",
    "    return words_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for id,text(untoken) table. returning dictionary.\n",
    "def bag_of_words(post):\n",
    "    post = nltk.word_tokenize(post)\n",
    "    post = [w.lower() for w in post]\n",
    "    post = [w for w in post if not w in stop_words and len(w)>2] \n",
    "    words_dictionary = dict([word, True] for word in post)\n",
    "\n",
    "    return words_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for id,text(token) table. returning dictionary.\n",
    "def bag_of_words(post):\n",
    "    post = [w.lower() for w in post]\n",
    "    post = [w for w in post if not w in stop_words and len(w)>2] \n",
    "    words_dictionary = dict([word, True] for word in post)\n",
    "\n",
    "    return words_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-ed0aeaf174df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfeatureset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mfeatureset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbag_of_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "# building list of features and labels\n",
    "featureset = []\n",
    "for i in range(len(df)):\n",
    "    featureset.append((bag_of_words(df.loc[i].text), df.loc[i].id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5876.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# length of test set\n",
    "len(featureset) / 4    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38393464942137506\n"
     ]
    }
   ],
   "source": [
    "middle_between_train_test = int(len(featureset) / 4)\n",
    "\n",
    "shuffle(featureset)\n",
    "test_set = featureset[:middle_between_train_test]\n",
    "train_set = featureset[middle_between_train_test:]\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "accuracy = nltk.classify.accuracy(classifier, test_set)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "               venerable = True           942828 : 449628 =    588.0 : 1.0\n",
      "                    abby = True           958176 : 449628 =    281.7 : 1.0\n",
      "                   henry = True           942828 : 197554 =    246.3 : 1.0\n",
      "                   feast = True           942828 : 734562 =    235.8 : 1.0\n",
      "                  philip = True           942828 : 449628 =    220.9 : 1.0\n",
      "                     st. = True           942828 : 110714 =    206.0 : 1.0\n",
      "                  priest = True           942828 : 449628 =    185.7 : 1.0\n",
      "                     hmm = True           178445 : 734562 =    156.0 : 1.0\n",
      "                    sooo = True           178445 : 449628 =    153.3 : 1.0\n",
      "                   katie = True           178445 : 449628 =    153.3 : 1.0\n",
      "                     mum = True           178445 : 449628 =    137.8 : 1.0\n",
      "                     mmm = True           178445 : 197554 =    132.7 : 1.0\n",
      "                 blessed = True           942828 : 958176 =    132.5 : 1.0\n",
      "                     ahh = True           178445 : 734562 =    123.3 : 1.0\n",
      "                   rosie = True           958176 : 303162 =    119.5 : 1.0\n",
      "                  virgin = True           942828 : 449628 =    119.3 : 1.0\n",
      "                catholic = True           942828 : 127064 =    111.5 : 1.0\n",
      "                   laura = True           178445 : 589736 =    111.0 : 1.0\n",
      "                    http = True           178445 : 303162 =    110.3 : 1.0\n",
      "                 prayers = True           942828 : 734562 =    110.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23504 entries, 0 to 23503\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        23504 non-null  int64 \n",
      " 1   text      23504 non-null  object\n",
      " 2   length    23504 non-null  object\n",
      " 3   richness  23504 non-null  object\n",
      " 4   commas    23504 non-null  object\n",
      " 5   dots      23504 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 13.0 MB\n"
     ]
    }
   ],
   "source": [
    "# show the memory usage of the data frame\n",
    "df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-ed2badcb4a2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetsizeof\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_set' is not defined"
     ]
    }
   ],
   "source": [
    "# show the memory usage of variable\n",
    "sys.getsizeof(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trying the vectorize way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramat\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    df.loc[i] = [df.loc[i].id, nltk.word_tokenize(df.loc[i].text)]\n",
    "    \n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df.loc[i].text = [x for x in df.loc[i].text if x not in stop_words and len(x) > 2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>richness</th>\n",
       "      <th>commas</th>\n",
       "      <th>dots</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>589736</td>\n",
       "      <td>[Much, funny, ., 2, points, ., As, mentioned, ...</td>\n",
       "      <td>47</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.0425532</td>\n",
       "      <td>0.0851064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>589736</td>\n",
       "      <td>[Harpers, ,, Harpers, ,, everywhere, ., Harper...</td>\n",
       "      <td>93</td>\n",
       "      <td>0.44086</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.0860215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589736</td>\n",
       "      <td>[In, an, earlier, post, ,, Johnathan, said, :,...</td>\n",
       "      <td>327</td>\n",
       "      <td>0.504587</td>\n",
       "      <td>0.0489297</td>\n",
       "      <td>0.0275229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>589736</td>\n",
       "      <td>[I, 'd, post, this, on, the, RTG, Blog, ,, but...</td>\n",
       "      <td>390</td>\n",
       "      <td>0.55641</td>\n",
       "      <td>0.0564103</td>\n",
       "      <td>0.0410256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>589736</td>\n",
       "      <td>[The, answer, to, the, first, question, lies, ...</td>\n",
       "      <td>29</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.0344828</td>\n",
       "      <td>0.0344828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text length  richness  \\\n",
       "0  589736  [Much, funny, ., 2, points, ., As, mentioned, ...     47  0.787234   \n",
       "1  589736  [Harpers, ,, Harpers, ,, everywhere, ., Harper...     93   0.44086   \n",
       "2  589736  [In, an, earlier, post, ,, Johnathan, said, :,...    327  0.504587   \n",
       "3  589736  [I, 'd, post, this, on, the, RTG, Blog, ,, but...    390   0.55641   \n",
       "4  589736  [The, answer, to, the, first, question, lies, ...     29  0.827586   \n",
       "\n",
       "      commas       dots  \n",
       "0  0.0425532  0.0851064  \n",
       "1   0.193548  0.0860215  \n",
       "2  0.0489297  0.0275229  \n",
       "3  0.0564103  0.0410256  \n",
       "4  0.0344828  0.0344828  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model : 0.44349897889720896\n"
     ]
    }
   ],
   "source": [
    "Xfeatures = df['text']\n",
    "ylabels = df['id']\n",
    "\n",
    "cv = CountVectorizer(tokenizer=lambda doc: doc, lowercase=False)\n",
    "X = cv.fit_transform(Xfeatures)\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,ylabels,test_size=0.16,random_state=42)\n",
    "\n",
    "x_train.shape\n",
    "\n",
    "y_train = y_train.astype('int')\n",
    "y_test = y_test.astype('int')\n",
    "clf = MultinomialNB()\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "print(\"Accuracy of Model :\",clf.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 141. MiB for an array with shape (18487680,) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-277b1e9f259f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlogit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"auto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lbfgs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlogit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy of Logit Model :\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1604\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1605\u001b[0m                       sample_weight=sample_weight)\n\u001b[1;32m-> 1606\u001b[1;33m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[0;32m   1607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1608\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1002\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1003\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[0;32m    942\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfprime\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    943\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 944\u001b[1;33m                 iprint=iprint, pgtol=tol, maxiter=max_iter)\n\u001b[0m\u001b[0;32m    945\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"warnflag\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m                 warnings.warn(\"lbfgs failed to converge. Increase the number \"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[1;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[1;32m--> 199\u001b[1;33m                            **opts)\n\u001b[0m\u001b[0;32m    200\u001b[0m     d = {'grad': res['jac'],\n\u001b[0;32m    201\u001b[0m          \u001b[1;34m'task'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'message'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m     \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m     \u001b[0mwa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mn\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mn\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mm\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m     \u001b[0miwa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[0mtask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'S60'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 141. MiB for an array with shape (18487680,) and data type float64"
     ]
    }
   ],
   "source": [
    "logit = LogisticRegression(random_state=0, multi_class=\"auto\", solver='lbfgs')\n",
    "logit.fit(x_train,y_train)\n",
    "\n",
    "print(\"Accuracy of Logit Model :\",logit.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
